{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV89h71OP-ti"
      },
      "source": [
        "# **Geometry-biased Transformers for Novel View Synthesis**\n",
        "\n",
        "### In this notebook you can evaluate our pre-trained models on sample datasets from the CO3D dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF6uBBEgYhYX"
      },
      "source": [
        "Install necessary libraries (might take a few minutes due to torch re-installation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6veiSH4_bP2B"
      },
      "outputs": [],
      "source": [
        "# Install torch==1.12\n",
        "!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "\n",
        "# Install PyTorch3D\n",
        "import sys\n",
        "import torch\n",
        "assert torch.__version__.startswith(\"1.12.\") and sys.platform.startswith(\"linux\")\n",
        "pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "version_str=\"\".join([f\"py3{sys.version_info.minor}_cu\", torch.version.cuda.replace(\".\",\"\"), f\"_pyt{pyt_version_str}\"])\n",
        "!pip install fvcore iopath\n",
        "!pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "\n",
        "# Install other libraries\n",
        "!pip install omegaconf hydra-core accelerate matplotlib plotly\n",
        "!pip install --upgrade --no-cache-dir gdown\n",
        "\n",
        "# Install co3d dataset\n",
        "!pip install \"git+https://github.com/facebookresearch/co3d.git\"\n",
        "\n",
        "# Setup GBT \n",
        "!git clone https://github.com/mayankgrwl97/gbt.git\n",
        "%cd gbt\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from omegaconf import OmegaConf\n",
        "from IPython.display import Image\n",
        "from gbt.model.model import GeometryBiasedTransformer\n",
        "from gbt.utils.image import (convert_tensor_to_images, save_images_as_gif,\n",
        "                             stitch_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9DRLMRZTqlo"
      },
      "source": [
        "Download pre-trained models ([link](https://drive.google.com/file/d/1eHeNba_qlsM-7iEiIlZw9XH9-VXqem7T/view?usp=sharing)) and sample data ([link](https://drive.google.com/file/d/1cvvS3nYatHVO6S_7EC3pE07Jt8DArJqP/view?usp=sharing)). Alternatively, run the following cell to download using `gdown`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nz-Pzm4p1onu"
      },
      "outputs": [],
      "source": [
        "!gdown 1eHeNba_qlsM-7iEiIlZw9XH9-VXqem7T\n",
        "!unzip runs.zip\n",
        "!rm runs.zip\n",
        "\n",
        "!gdown 1cvvS3nYatHVO6S_7EC3pE07Jt8DArJqP\n",
        "!unzip data.zip\n",
        "!rm data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpsFuY6eUMBz"
      },
      "source": [
        "Load pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKKv2DfP3rR4"
      },
      "outputs": [],
      "source": [
        "cfg = OmegaConf.load('configs/cat_agnostic_gbt.yaml')\n",
        "model = GeometryBiasedTransformer(cfg.model)\n",
        "device = cfg.infer.device\n",
        "model.load_state_dict(torch.load(cfg.infer.load_path))\n",
        "model = model.to(device).eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBt8r_YhUV8Y"
      },
      "source": [
        "Load sample data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77YO5WFy4lo5"
      },
      "outputs": [],
      "source": [
        "with open('data/134_15451_31119.pkl', 'rb') as handle:\n",
        "    batch = pickle.load(handle)\n",
        "\n",
        "input_views = batch[\"sparse_input_images\"].to(device)  # (B, num_input_views, C, H, W)\n",
        "input_cameras = batch[\"sparse_input_cameras\"]  # 2-d list of cameras of shape (B, num_input_views)\n",
        "query_img = batch[\"sparse_query_images\"].to(device)  # (B, num_query_views, C, H, W)\n",
        "query_cameras = batch[\"sparse_query_cameras\"]  # 2-d list of cameras of shape (B, num_query_views)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVTKJc3sYXPR"
      },
      "source": [
        "Infer novel-view synthesis for multiple views and visualize as a revolving GIF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hk22YFE5M-X"
      },
      "outputs": [],
      "source": [
        "num_query_views = query_img.shape[1]\n",
        "stitched_images = []\n",
        "image_size = tuple(query_img.shape[-2:])\n",
        "for q_idx in range(num_query_views):\n",
        "    pred_img = model.infer(input_views=input_views[:1], input_cameras=input_cameras[:1],\n",
        "                            query_cameras=[query_cameras[0][q_idx]], image_size=image_size)  # (1, H*W, 3)\n",
        "    pred_img = pred_img.reshape(1, *image_size, 3) # (1, H, W, 3)\n",
        "\n",
        "    # (N, H, W, 3) - [0, 1]\n",
        "    input_image, query_image, pred_image = convert_tensor_to_images(\n",
        "        input_views[0], query_img[:1, q_idx], pred_img)\n",
        "\n",
        "    stitched_image = stitch_images(input_image, query_image, pred_image)\n",
        "    stitched_image = (stitched_image * 255).astype(np.uint8)\n",
        "    stitched_images.append(stitched_image)\n",
        "\n",
        "save_images_as_gif(save_path=\"predicted.gif\", images=stitched_images, fps=15)\n",
        "\n",
        "print(\"        Input View 1                  Input View 2                  Input View 3                  Ground Truth                   Predicted          \")\n",
        "Image(open(\"predicted.gif\", 'rb').read())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}